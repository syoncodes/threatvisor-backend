import subprocess
import os
import requests
from pymongo import MongoClient
import re
from datetime import datetime
import json
from bs4 import BeautifulSoup

# Connect to MongoDB
client = MongoClient("mongodb://syonb:syonsmart@ac-0w6souu-shard-00-00.jfanqj5.mongodb.net:27017,ac-0w6souu-shard-00-01.jfanqj5.mongodb.net:27017,ac-0w6souu-shard-00-02.jfanqj5.mongodb.net:27017/?replicaSet=atlas-yytbi1-shard-0&ssl=true&authSource=admin")
db = client['test']
collection = db['organizations']

def get_exploits_by_service_and_version(service, version):
    cmd = ['searchsploit', service, version]
    result = subprocess.run(cmd, capture_output=True, text=True)
    lines = result.stdout.splitlines()
    exploit_paths = [line.split('|')[-1].strip() for line in lines if ".txt" in line]
    
    exploits = []
    for path in exploit_paths:
        exploit_id = path.split('/')[-1].split('.')[0]
        exploit_link = f"https://www.exploit-db.com/exploits/{exploit_id}"
        path_cmd = ['searchsploit', '--path', exploit_id]
        path_result = subprocess.run(path_cmd, capture_output=True, text=True)
        full_path = path_result.stdout.split("Path:")[1].split("\n")[0].strip()
        
        with open(full_path, 'r') as file:
            exploit_content = file.read()
        
        exploit_cmd = ['searchsploit', '+x', exploit_id]
        exploit_result = subprocess.run(exploit_cmd, capture_output=True, text=True)
        exploit_details = exploit_result.stdout.strip()

        exploits.append({
            "title": f"ExploitDB {exploit_id}",
            "link": exploit_link,
            "content": exploit_content,
            "source": "ExploitDB"
        })

    search_command = ["msfconsole", "-q", "-x", f"search {service} version:{version}; exit"]
    search_result = subprocess.run(search_command, capture_output=True, text=True).stdout
    lines = search_result.split("\n")
    exploit_name = None
    for line in lines:
        if "exploit/" in line:
            exploit_name = line.split()[1]
            break

    if exploit_name:
        info_command = ["msfconsole", "-q", "-x", f"use {exploit_name}; info; exit"]
        info_result = subprocess.run(info_command, capture_output=True, text=True).stdout
        exploits.append({
            "title": f"Metasploit {exploit_name}",
            "content": info_result,
            "source": "Metasploit"
        })

    return exploits

def get_cve_details_from_api(cve_id):
    try:
        api_url = f"https://cveawg.mitre.org/api/cve/{cve_id}"
        response = requests.get(api_url)
        response.raise_for_status()
        data = response.json()

        cve_details = {
            "title": f"CVE {data['cveMetadata']['cveId']}",
            "link": f"https://www.cve.org/CVERecord?id={cve_id}",
            "content": data['containers']['cna']['descriptions'][0]['value'],
            "source": "MITRE"
        }

        return cve_details
    except Exception as e:
        print(f"Error fetching CVE details from API: {e}")
        return None

def get_exploitdb_details(cve_id):
    cmd = ['searchsploit', '--cve', cve_id]
    result = subprocess.run(cmd, capture_output=True, text=True)
    lines = result.stdout.splitlines()
    exploit_paths = [line.split('|')[-1].strip() for line in lines if ".txt" in line]
    
    exploits = []
    for path in exploit_paths:
        exploit_id = path.split('/')[-1].split('.')[0]
        exploit_link = f"https://www.exploit-db.com/exploits/{exploit_id}"
        path_cmd = ['searchsploit', '--path', exploit_id]
        path_result = subprocess.run(path_cmd, capture_output=True, text=True)
        full_path = path_result.stdout.split("Path:")[1].split("\n")[0].strip()
        
        with open(full_path, 'r') as file:
            exploit_content = file.read()
        
        exploit_cmd = ['searchsploit', '+x', exploit_id]
        exploit_result = subprocess.run(exploit_cmd, capture_output=True, text=True)
        exploit_details = exploit_result.stdout.strip()

        exploits.append({
            "title": f"CVE {cve_id}",
            "link": exploit_link,
            "content": exploit_content,
            "source": "ExploitDB"
        })

    return exploits

def get_metasploit_details(cve_id):
    search_command = ["msfconsole", "-q", "-x", f"search cve:{cve_id}; exit"]
    search_result = subprocess.run(search_command, capture_output=True, text=True).stdout
    lines = search_result.split("\n")
    exploit_name = None
    for line in lines:
        if "exploit/" in line:
            exploit_name = line.split()[1]
            break

    if exploit_name:
        info_command = ["msfconsole", "-q", "-x", f"use {exploit_name}; info; exit"]
        info_result = subprocess.run(info_command, capture_output=True, text=True).stdout
        return {
            "title": f"CVE {cve_id}",
            "content": info_result,
            "source": "Metasploit"
        }
    else:
        return None

def get_nvd_details(cve_id):
    try:
        url = f"https://services.nvd.nist.gov/rest/json/cve/1.0/{cve_id}"
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()
        return data
    except requests.exceptions.HTTPError as http_err:
        print(f"HTTP error occurred: {http_err}")
    except json.JSONDecodeError as json_err:
        print(f"JSON decoding error occurred: {json_err}")
    except Exception as err:
        print(f"An error occurred: {err}")
    return None

def get_cwe_details(cwe_id):
    try:
        api_url = f"https://cwe.mitre.org/data/definitions/{cwe_id}.html"
        response = requests.get(api_url)
        response.raise_for_status()

        soup = BeautifulSoup(response.content, 'html.parser')

        def extract_section_text(section_id):
            section = soup.find(id=section_id)
            if section:
                parent_div = section.find_next('div', class_='expandblock')
                if parent_div:
                    return parent_div.get_text(separator='\n', strip=True)
            return "Not available"

        description = extract_section_text('Description')
        extended_description = extract_section_text('Extended_Description')
        if extended_description == "Not available":
            extended_description = description

        observed_examples = extract_section_text('Observed_Examples')
        detection_methods = extract_section_text('Detection_Methods')
        demonstrative_examples = extract_section_text('Demonstrative_Examples')

        cwe_details = {
            "title": f"CWE {cwe_id}",
            "link": api_url,
            "observed_examples": observed_examples,
            "detection_methods": detection_methods,
            "demonstrative_examples": demonstrative_examples,
            "extended_description": extended_description,
            "source": "CWE"
        }

        return cwe_details
    except Exception as e:
        print(f"Error fetching CWE details from API: {e}")
        return None

def get_wasc_details(wasc_id):
    try:
        api_url = f"https://owasp.org/www-project-web-application-security/wasc/{wasc_id}.html"
        response = requests.get(api_url)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')

        def extract_section_text(header_text):
            header = soup.find('h2', text=header_text)
            if header:
                next_sibling = header.find_next_sibling()
                paragraphs = []
                while next_sibling and next_sibling.name != 'h2':
                    if next_sibling.name == 'p':
                        paragraphs.append(next_sibling.get_text(separator='\n', strip=True))
                    next_sibling = next_sibling.find_next_sibling()
                return "\n".join(paragraphs)
            return "Not available"

        description = extract_section_text('Description')
        extended_description = extract_section_text('Extended Description')
        if extended_description == "Not available":
            extended_description = description

        wasc_details = {
            "title": f"WASC {wasc_id}",
            "link": api_url,
            "content": extended_description,
            "source": "WASC"
        }

        return wasc_details
    except Exception as e:
        print(f"Error fetching WASC details from API: {e}")
        return None

def search_cve_in_document(cve_id):
    cve_api_details = get_cve_details_from_api(cve_id)
    exploitdb_exploits = get_exploitdb_details(cve_id)
    metasploit_exploit = get_metasploit_details(cve_id)
    nvd_details = get_nvd_details(cve_id)

    combined_results = []
    if cve_api_details:
        combined_results.append(cve_api_details)
    if exploitdb_exploits:
        combined_results.extend(exploitdb_exploits)
    if metasploit_exploit:
        combined_results.append(metasploit_exploit)
    if nvd_details:
        combined_results.append(nvd_details)

    return combined_results

def extract_ids_from_document(document):
    cve_ids = set()
    cwe_ids = set()
    wasc_ids = set()

    for endpoint in document.get('endpoints', []):
        for item in endpoint.get('items', []):
            results = item.get('results', {})
            if results:
                for result in results.values():
                    cwe_ids.update(result.get('CWE', []))
                    wasc_ids.update(result.get('WASC', []))
                    cve_ids.update(result.get('CVE', []))

    return {
        'CVE': list(cve_ids),
        'CWE': list(cwe_ids),
        'WASC': list(wasc_ids)
    }

def update_document_with_service_exploits(user_id, endpoint_index, item_index, exploit_data):
    document = collection.find_one({"_id": user_id})
    exploits = document['endpoints'][endpoint_index]['items'][item_index].get('exploits', {})

    for key, value in exploit_data.items():
        if key in exploits:
            existing_titles = [exploit['title'] for exploit in exploits[key]]
            new_exploits = [exploit for exploit in value if exploit['title'] not in existing_titles]
            exploits[key].extend(new_exploits)
        else:
            exploits[key] = value

    collection.update_one(
        {"_id": user_id},
        {"$set": {f'endpoints.{endpoint_index}.items.{item_index}.exploits': exploits}}
    )

def main():
    for document in collection.find({"endpoints.items.service": "Domain"}):
        user_id = document['_id']
        for endpoint_index, endpoint in enumerate(document['endpoints']):
            for item_index, item in enumerate(endpoint['items']):
                if item['service'] == "Domain" and 'url' in item:
                    domain = item['url']
                    scan_type = item.get('scan', 'passive')
                    last_scan_date = item.get('scanned', datetime.min)

                    ids = extract_ids_from_document(document)
                    cve_ids = ids['CVE']
                    cwe_ids = ids['CWE']
                    wasc_ids = ids['WASC']

                    for cve_id in cve_ids:
                        print(f"Searching for exploits related to CVE {cve_id} for domain {domain}...")
                        cve_results = search_cve_in_document(cve_id)
                        update_document_with_service_exploits(user_id, endpoint_index, item_index, {f"CVE {cve_id}": cve_results})
                        print(f"Updated exploits for CVE {cve_id} for domain {domain}.")

                    for cwe_id in cwe_ids:
                        print(f"Searching for details related to CWE {cwe_id}...")
                        cwe_results = get_cwe_details(cwe_id)
                        if cwe_results:
                            update_document_with_service_exploits(user_id, endpoint_index, item_index, {f"CWE {cwe_id}": [cwe_results]})
                            print(f"Updated details for CWE {cwe_id}.")

                    for wasc_id in wasc_ids:
                        print(f"Searching for details related to WASC {wasc_id}...")
                        wasc_results = get_wasc_details(wasc_id)
                        if wasc_results:
                            update_document_with_service_exploits(user_id, endpoint_index, item_index, {f"WASC {wasc_id}": [wasc_results]})
                            print(f"Updated details for WASC {wasc_id}.")

import time

if __name__ == "__main__":
    while True:
        main()
        time.sleep(60)
